{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract images from a live video to create a dataset\n",
    "\n",
    "We now use a simple GUI to generate new dataset for image segmentation. \n",
    "\n",
    "Here are the steps:\n",
    "\n",
    "\n",
    "* Get an image from a camera (could later be a video or images). \n",
    "* Click on the video to extract one image, and then click again to label the oject on the image.\n",
    "* Save image, coordinate and mask to the dataset.\n",
    "* Split images and mask as a train and validation dataset.\n",
    "\n",
    "You want at least 150 imgaes to get ok tracking. We can further improve the model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from unetTracker.trackingProject import TrackingProject\n",
    "from unetTracker.dataset import UNetDataset\n",
    "from unetTracker.camera import USBCamera, bgr8_to_jpeg\n",
    "from unetTracker.unetGUI import LabelFromCameraGUI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a TrackingProject object from file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directory: /home/kevin/Documents/trackingProjects/faceTrack\n",
      "Loading /home/kevin/Documents/trackingProjects/faceTrack/config.yalm\n",
      "{'augmentation_HorizontalFlipProb': 0.0, 'augmentation_RandomBrightnessContrastProb': 0.2, 'augmentation_RandomSizedCropProb': 1.0, 'augmentation_RotateProb': 0.3, 'image_size': [480, 640], 'labeling_ImageEnlargeFactor': 2.0, 'name': 'faceTrack', 'normalization_values': {'means': [0.5110162496566772, 0.4608974754810333, 0.4772901237010956], 'stds': [0.2727729380130768, 0.2578601539134979, 0.256255567073822]}, 'object_colors': [(0.0, 0.0, 255.0), (255.0, 0.0, 0.0), (255.0, 255.0, 0.0), (128.0, 0.0, 128.0)], 'objects': ['nose', 'chin', 'rEye', 'lEye'], 'target_radius': 10}\n"
     ]
    }
   ],
   "source": [
    "project = TrackingProject(name=\"faceTrack\",root_folder = \"/home/kevin/Documents/trackingProjects/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kevin/Documents/trackingProjects/faceTrack/dataset/masks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.mask_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset object\n",
    "\n",
    "A Dataset object is created to save labeled images, masks and coordinates. It is also used to load the data into memory when training your model. This is a class inherited from `torch.utils.data.Dataset`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = UNetDataset(image_dir=project.image_dir, mask_dir=project.mask_dir, coordinate_dir=project.coordinate_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can know how many images are in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also load any of the images in your dataset, together with mask and coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image,mask,coordinates = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we are getting an image, mask, and coordinates of objects.\n",
    "\n",
    "The image and mask are `torch.tensor` instead of `np.array`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crw-rw----+ 1 root video 81, 1 Dez 10 10:01 /dev/video1\n",
      "crw-rw----+ 1 root video 81, 0 Dez 10 10:01 /dev/video0\n"
     ]
    }
   ],
   "source": [
    "!ls -ltrh /dev/video*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = USBCamera(width=project.image_size[1], height=project.image_size[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "image = camera.read()\n",
    "print(image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e65eb2df01944e9a43215e1c3605b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgWidget = widgets.Image(format='jpeg')\n",
    "imgWidget.value = bgr8_to_jpeg(image)\n",
    "display(imgWidget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the GUI to extract and label frames from a camera \n",
    "\n",
    "1. Click on the top left image to capture a frame from the camera feed. A larger image will appear below the entry boxes for the coordinates. \n",
    "2. Your body parts are listed above the large image. In the large image, click on the object that is selected in the radio button. You should see a label apper in the picture at the very bottom.\n",
    "3. Repeat for all the body parts visible on the image. If you leave the coordinate of an object at 0,0, it is considered not in the image.\n",
    "4. Once all the body parts are labeled, click on `Save labelled frame`.\n",
    "5. Go back to step 1 and repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4cd4785d0d749cca01972b7f7dff6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LabelFromCameraGUI(children=(HBox(children=(Image(value=b'', format='jpeg', height='240.0', width='320.0'), Im…"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelFromCameraGUI(camera,project,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you click on `Save labelled frame`, a new data point is added to your dataset. This is stored in a subdirectory of your project directory called `dataset`. There are 3 directories there: images, masks and coordinates. This data will be used to train the network and assess tracking quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
